2021年12月10日-12月28日：每日论文

## 量化/压缩

Learned Queries for Efficient Local Attention
**标题**：用于高效局部关注的学习型查询
**链接**：https://arxiv.org/abs/2112.11435

**作者**：Moab Arar,Ariel Shamir,Amit H. Bermano
**机构**：Tel-Aviv University, Reichman University
**摘要**：视觉变换器（ViT）是功能强大的视觉模型。与前几年主导视觉研究的卷积神经网络不同，视觉变换器具有捕获数据中长期相关性的能力。尽管如此，任何转换器体系结构的一个组成部分，即自我注意机制，都会受到高延迟和低效内存利用率的影响，因此不太适合高分辨率输入图像。为了缓解这些缺点，分层视觉模型在非交错窗口上局部地采用了自我注意。这种松弛降低了输入大小的线性复杂性；但是，它限制了跨窗口交互，影响了模型性能。在本文中，我们提出了一种新的平移不变局部注意层，称为查询和参与（QnA），它以重叠的方式局部聚集输入，就像卷积一样。QnA背后的关键思想是引入学习的查询，它允许快速高效的实现。我们通过将我们的层合并到分层视觉转换器模型中来验证其有效性。我们展示了速度和内存复杂性的改进，同时实现了与最先进模型相当的精度。最后，我们的层可以很好地扩展窗口大小，所需的内存最多可以减少10倍，而速度比现有方法快5倍。

---

Elastic-Link for Binarized Neural Network
**标题**：二值化神经网络的弹性连接
**链接**：https://arxiv.org/abs/2112.10149

**作者**：Jie Hu,Wu Ziheng,Vince Tan,Zhilin Lu,Mengze Zeng,Enhua Wu
**机构**： State Key Lab of Computer Science, ISCAS & University of Chinese Academy of Sciences,  Department of Electronic Engineering, Tsinghua University,  Alibaba Group,  ByteDance Inc.,  University of Macau
**备注**：AAAI2022
**摘要**：最近的研究表明，二值化神经网络（BNN）能够极大地降低计算成本和内存占用，便于在资源受限的设备上部署模型。然而，与全精度对应设备相比，BNN的精度严重下降。到目前为止，旨在缩小这种精度差距的研究主要集中在具有很少或没有1x1卷积层的特定网络架构上，对于这些架构，标准的二值化方法无法很好地工作。由于1x1卷积在现代体系结构（如GoogleNet、ResNet、DenseNet）的设计中很常见，因此开发一种有效地对其进行二值化的方法对于BNN得到更广泛的采用至关重要。在这项工作中，我们提出了一个“弹性链接”（EL）模块，通过自适应地将实值输入特征添加到后续卷积输出特征来丰富BNN中的信息流。所提出的EL模块易于实现，可与BNN的其他方法结合使用。我们证明，在BNNs中添加EL可以显著改善具有挑战性的大规模ImageNet数据集。例如，我们将二值化ResNet26的顶级精度从57.9%提高到64.0%。EL也有助于二值化MobileNet训练的收敛，其精度达到了56.4%的top-1。最后，通过对ReActNet的集成，它产生了一个新的最先进的结果，即71.9%的top-1精度。

---

Network Compression via Central Filter
**标题**：通过中央过滤进行网络压缩
**链接**：https://arxiv.org/abs/2112.05493

**作者**：Yuanzhi Duan,Xiaofang Hu,Yue Zhou,Qiang Liu,Shukai Duan
**机构**：College of Artificial Intelligence, Southwest University, China, College of Electronics and Information Engineering, Southwest University, China, Brain-inspired Computing & Intelligent Control of Chongqing Key Lab, China, Harbin Institute of Technology, China
**摘要**：神经网络剪枝在降低深层网络模型复杂度方面具有显著的性能。最近的网络修剪方法通常侧重于删除网络中不重要或冗余的过滤器。在本文中，通过探索特征映射之间的相似性，我们提出了一种新的过滤器修剪方法，即中心过滤器（CF），该方法表明，经过适当调整后，一个过滤器近似等于一组其他过滤器。我们的方法基于这样一个发现：无论输入图像的数量多少，特征图之间的平均相似性变化很小。基于这一发现，我们在特征图上建立相似图，并计算每个节点的贴近度中心度来选择中心滤波器。此外，我们还设计了一种直接调整中央滤波器对应的下一层权值的方法，有效地减少了剪枝带来的误差。通过在各种基准网络和数据集上的实验，CF产生了最先进的性能。例如，使用ResNet-56，CF通过删除47.1%的参数减少了大约39.7%的触发器，CIFAR-10的精度甚至提高了0.33%。使用GoogLeNet，CF通过删除55.6%的参数，减少了大约63.2%的触发器，在CIFAR-10上的top-1精度只有0.35%的小损失。使用ResNet-50，CF通过删除36.9%的参数减少了大约47.9%的触发器，而ImageNet上的top-1精度仅损失了1.07%。这些代码可在以下网址获得：https://github.com/8ubpshLR23/Central-Filter.

---







## 摘要/多模态

Consistency and Coherence from Points of Contextual Similarity
**标题**：从语境相似性看一致性与连贯性
**链接**：https://arxiv.org/abs/2112.11638

**作者**：Oleg Vasilyev,John Bohannon
**机构**：Primer Technologies Inc., San Francisco, California
**备注**：9 pages, 7 figures, 1 table
**摘要**：事实一致性是总结评估的一个重要维度，尤其是当总结生成变得更加流畅和连贯时。最近专门针对事实一致性提出的ESTIME度量，在一致性和流利性方面与人类专家得分具有高度相关性，而原则上仅限于评估字典重叠度较高的文本摘要对。这对于当前的摘要样式来说不是问题，但它可能会成为未来摘要系统的障碍，或者成为评估针对文本的任意声明的障碍。在这项工作中，我们推广了该方法，使其适用于任何文本摘要对。由于ESTIME使用了上下文相似点，因此它可以深入了解从不同层获取的信息的有用性。我们观察到，除了几个最低层之外，几乎所有层中都存在有用的信息。为了保持连贯性和流畅性——注重本地文本细节——最有用的层次靠近顶部（但不在顶部）；对于连贯性和相关性，我们发现了一幅更为复杂和有趣的画面。

---

Topic-Aware Encoding for Extractive Summarization
**标题**：用于抽取摘要的主题感知编码
**链接**：https://arxiv.org/abs/2112.09572

**作者**：Mingyang Song,Liping Jing
**机构**：Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University, Beijing, China
**备注**：4 pages, 0 figures
**摘要**：文档摘要提供了一种工具，可以更快地理解文本文档的集合，并具有多种实际应用。随着在线文本数据的增长，近年来提出了许多摘要模型。基于Sequence-to-Sequence（Seq2Seq）的神经摘要模型由于其高性能在摘要领域得到了最广泛的应用。这是因为编码时充分考虑了文本中的语义信息和结构信息。然而，现有的抽取式摘要模型很少关注并使用中心主题信息来辅助摘要的生成，这导致模型不能保证在主主题下生成摘要。一份冗长的文档可以跨越多个主题，而一份摘要不能公正地涵盖所有主题。因此，生成高质量摘要的关键是确定中心主题并在此基础上构建摘要，特别是对于长文档。为了解决这个问题，我们提出了一种基于主题的文档摘要编码方法。该模型有效地结合了句法层面和话题层面的信息，构建了一个全面的句子表示。具体地，在基于神经的句子级表示学习中添加神经主题模型，以充分考虑中心主题信息以捕获原始文档中的关键内容。在三个公共数据集上的实验结果表明，我们的模型优于最先进的模型。

---

CONFIT: Toward Faithful Dialogue Summarization with  Linguistically-Informed Contrastive Fine-tuning
**标题**：Confit：以语言信息为基础的对比微调走向忠实的对话总结
**链接**：https://arxiv.org/abs/2112.08713

**作者**：Xiangru Tang,Arjun Nair,Borui Wang,Bingyao Wang,Jai Desai,Aaron Wade,Haoran Li,Asli Celikyilmaz,Yashar Mehdad,Dragomir Radev
**摘要**：摘要生成中的事实不一致严重限制了抽象对话摘要的实际应用。虽然通过使用预先训练的模型已经取得了重大进展，但在人类评估过程中发现了大量的幻觉内容。对于文本摘要，预训练的模型通常使用交叉熵损失进行微调，这可能不是最佳策略。在这项工作中，我们提供了一个带有注释数据的事实错误类型，以突出错误的类型，并摆脱对事实性的二元理解。我们进一步提出了一种训练策略，通过一种新的对比微调，即ConFiT，提高总结的事实一致性和整体质量。基于我们的语言信息错误类型学，我们设计了不同的模块化目标，每个目标针对特定类型。具体来说，我们利用带有错误的硬负样本来减少事实不一致的产生。为了捕捉说话人之间的关键信息，我们还设计了一个特定的对话。通过使用人类评估和自动忠实度度量，我们表明我们的模型显著减少了对话摘要、SAMSum语料库中的各种事实错误。此外，我们的模型可以推广到会议摘要、AMI语料库，并且在单词重叠度量方面，它在两个数据集上的得分显著高于大多数基线。

----

Exploring Neural Models for Query-Focused Summarization
**标题**：探索面向查询的摘要神经模型
**链接**：https://arxiv.org/abs/2112.07637

**作者**：Jesse Vig,Alexander R. Fabbri,Wojciech Kryściński
**机构**：Wojciech Kry´sci´nski∗, Salesforce Research
**摘要**：以查询为中心的摘要（QFS）旨在生成能够回答特定兴趣问题的摘要，从而实现更好的用户控制和个性化。虽然最近发布的数据集，如QMSum或AQuaMuSe，促进了QFS的研究工作，但该领域缺乏对适用建模方法广阔空间的全面研究。在本文中，我们对QFS的神经方法进行了系统的探索，考虑了两类方法：两阶段提取抽象解和端到端模型。在这些类别中，我们调查了现有的方法，并提出了两种模型扩展，它们在QMSum数据集上实现了最先进的性能，其差值高达3.38胭脂-1、3.72胭脂-2、，和3.28 ROUGE-L。通过定量实验，我们强调了不同模型配置之间的权衡，并探索了摘要任务之间的转换能力。代码和检查点是公开的：

---

Unified Multimodal Pre-training and Prompt-based Tuning for  Vision-Language Understanding and Generation
**标题**：用于视觉语言理解和生成的统一多模态预训练和基于提示的调优
**链接**：https://arxiv.org/abs/2112.05587

**作者**：Tianyi Liu,Zuxuan Wu,Wenhan Xiong,Jingjing Chen,Yu-Gang Jiang
**机构**：Shanghai Key Lab of Intelligent Information Processing, School of Computer Science, Fudan Univeristy, University of California, Santa Barbara
**摘要**：大多数现有的视觉语言预训练方法侧重于理解任务，并在预训练期间使用类似于BERT的目标（蒙面语言建模和图像文本匹配）。尽管它们在许多理解下游任务中表现良好，例如，视觉问答、图像文本检索和视觉蕴涵，但它们不具备生成信息的能力。为了解决这个问题，我们提出了视觉语言理解和生成的统一多模态预训练（UniVL）。建议的UniVL能够处理理解任务和生成任务。我们扩展了现有的预训练范式，该范式仅使用随机掩码和因果掩码，即掩盖未来标记的三角形掩码，这样预先训练的模型可以通过设计具有自回归生成能力。我们将之前的几个理解任务描述为文本生成任务，并建议使用基于提示的方法对不同的下游任务进行微调。我们的实验表明，在使用相同的模型时，理解任务和生成任务之间存在一种折衷，改进这两种任务的可行方法是使用更多的数据。我们的UniVL框架在理解任务和生成任务方面取得了与最近的视觉语言预训练方法相当的性能。此外，我们还演示了基于提示的微调更有效地处理数据——在少数镜头场景中，它优于区分性方法。

